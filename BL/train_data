import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset, random_split
import pandas as pd
import ast
from mlp_model_2 import MLP  

if __name__ == "__main__":

    df = pd.read_csv('gen3.csv')
    

    df['pns_bounds'] = df['pns_bounds'].astype(str)
    

    labels = torch.tensor(df['pns_bounds'].str.replace(r'\(|\)', '', regex=True).str.split(',').str[0].astype(float), dtype=torch.float32)
    

    df['subpopulation_values'] = df['subpopulation_values'].apply(ast.literal_eval)


    features = torch.tensor(df['subpopulation_values'].tolist(), dtype=torch.float32)


    dataset = TensorDataset(features, labels)


    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=64)


    model = MLP()
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    num_epochs = 600
    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        for inputs, labels in train_loader:
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels.view(-1, 1))
            loss.backward()
            optimizer.step()
            running_loss += loss.item() * inputs.size(0)
        

        if (epoch + 1) % 50 == 0:
            model.eval()
            val_loss = 0.0
            with torch.no_grad():
                for inputs, labels in val_loader:
                    outputs = model(inputs)
                    loss = criterion(outputs, labels.view(-1, 1))
                    val_loss += loss.item() * inputs.size(0)
            print(f'Epoch [{epoch + 1}/{num_epochs}], '
                  f'Training Loss: {running_loss / len(train_dataset):.4f}, '
                  f'Validation Loss: {val_loss / len(val_dataset):.4f}')

    print('Finished Training')


    test_df = pd.read_csv('test_data.csv')

    test_df['subpopulation_values'] = test_df['subpopulation_values'].apply(ast.literal_eval)


    test_features = torch.tensor(test_df['subpopulation_values'].tolist(), dtype=torch.float32)
    test_labels = torch.tensor(test_df['pns_bounds'].tolist(), dtype=torch.float32)


    test_dataset = TensorDataset(test_features, test_labels)
    test_loader = DataLoader(test_dataset, batch_size=64)


    model.eval()
    test_loss = 0.0
    with torch.no_grad():
        for inputs, labels in test_loader:
            outputs = model(inputs)
            loss = criterion(outputs, labels.view(-1, 1))
            test_loss += loss.item() * inputs.size(0)


    mse = test_loss / len(test_dataset)
    print(f'Test MSE: {mse:.4f}')
