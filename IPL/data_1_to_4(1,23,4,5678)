import numpy as np
import pandas as pd
from collections import Counter
from scipy.stats import bernoulli
from tqdm import tqdm 

def generate_exp_sample(num_features, bernoulli_params_UZ, bernoulli_params_UX, bernoulli_params_UY, coefficients_MX, coefficients_MY, C):
    """
    Generate a single experimental sample.
    """
    # Randomly generate ( UZ1, ..., UZ20, UX, UY)
    UZ_values = np.random.binomial(1, bernoulli_params_UZ, size=num_features)
    UX_value = np.random.binomial(1, bernoulli_params_UX)
    UY_value = np.random.binomial(1, bernoulli_params_UY)

    # Calculate MX and MY
    MX_value = np.dot(UZ_values, coefficients_MX)
    MY_value = np.dot(UZ_values, coefficients_MY)

    # Randomly generate X using Bernoulli(0.5)
    X_value = np.random.binomial(1, 0.5)

    # Calculate Y using fY(X, MY, UY)
    Y_value = 1 if (C + MX_value + UY_value > 0 and C + MX_value + UY_value < 1) or \
                   (C + MX_value + UY_value > 1 and C + MX_value + UY_value < 2) else 0

    # Create an experimental sample
    sample = {'UZ': UZ_values, 'UX': UX_value, 'UY': UY_value, 'X': X_value, 'Y': Y_value}
    return sample

def generate_exp_samples(num_samples, num_features, bernoulli_params_UZ, bernoulli_params_UX, bernoulli_params_UY, coefficients_MX, coefficients_MY, C):
    """
    Generate multiple experimental samples.
    """
    experimental_samples = []
    for _ in tqdm(range(num_samples), desc="Generating Experimental Samples"):
        sample = generate_exp_sample(num_features, bernoulli_params_UZ, bernoulli_params_UX, bernoulli_params_UY, coefficients_MX, coefficients_MY, C)
        experimental_samples.append(sample)
    return experimental_samples

def generate_obs_samples(num_samples, num_features, bernoulli_params_UZ, bernoulli_params_UX, bernoulli_params_UY, coefficients_MX, coefficients_MY, C):
    """
    Generate observational samples.
    """
    observational_samples = []
    for _ in tqdm(range(num_samples), desc="Generating Observational Samples"):

        UZ_values = np.random.binomial(1, bernoulli_params_UZ, size=num_features)
        UX_value = np.random.binomial(1, bernoulli_params_UX)
        UY_value = np.random.binomial(1, bernoulli_params_UY)

        # Convert UX to 1-dimensional array
        UX_value = np.array([UX_value])

        # Calculate MX and MY
        MX_value = np.dot(UZ_values, coefficients_MX)
        MY_value = np.dot(UZ_values, coefficients_MY)

        # Calculate X using fX(MX, UX)
        X_value = 1 if MX_value + UX_value[0] > 0.5 else 0

        # Calculate Y using fY(X, MY, UY)
        Y_value = 1 if (C + MX_value + UY_value > 0 and C + MX_value + UY_value < 1) or \
                       (C + MX_value + UY_value > 1 and C + MX_value + UY_value < 2) else 0

        # Create an observational sample
        sample = {'UZ': UZ_values, 'UX': UX_value, 'UY': UY_value, 'X': X_value, 'Y': Y_value}
        observational_samples.append(sample)

    return observational_samples

def select_over_1300(experimental_samples):
    """
    Select samples with UZ values that occurred 1300 times or more.
    """
    # Extract UZ values from observational samples
    UZ_samples = [tuple(sample['UZ']) for sample in experimental_samples]

    # Count occurrences of each UZ value combination
    uz_counter = Counter(UZ_samples)
    selected_samples =[]
    # Use tqdm to iterate over the experimental samples
    for sample in tqdm(experimental_samples, desc="Selecting Samples over 1300"):
        if uz_counter[tuple(sample['UZ'])] >= 1300:
            selected_samples.append(sample)
    return selected_samples

def calculate_Y(X, MY, UY):
    num_observed_features = 15  # Observed features의 개수
    C = -0.77953605542

    bernoulli_params_UZ = ([0.524110233482, 0.689566064108, 0.180145428970, 0.317153536644, 0.046268153873,
                      0.340145244411, 0.100912238566, 0.772038172066, 0.913108434869, 0.364272299067,
                      0.063667554704, 0.454839320009, 0.586687215140, 0.018824647595, 0.871017316787])

    bernoulli_params_UX = 0.601680857267
    bernoulli_params_UY = 0.497668975278

    # Coefficients for MX and MY
    coefficients_MX = np.array([0.843870221861 , 0.178759296447, -0.372349746729, -0.950904544846, -0.439457721339,
                                -0.725970103834, -0.791203963585, -0.843183562918, -0.68422616618, -0.782051030131,
                                -0.434420454146, -0.445019418094, 0.751698021555, -0.185984172192, 0.191948271392])
                                #0.401334543567 ,  0.331387702568, 0.522595634402, -0.928734581669, 0.203436441511])

    coefficients_MY = np.array([-0.453251661832,  0.424563325534, 0.0924810605305 , 0.312680246141, 0.7676961338,
                                0.124337421843, -0.435341306455, 0.248957751703, -0.161303883519,-0.537653062121,
                                -0.222087991408, 0.190167775134, -0.788147770713, -0.593030174012, -0.308066297974])
                                #0.218776507777, -0.751253645088, -0.11151455376 , 0.785227235182, -0.568046522383])

    MY_array = np.array(MY, dtype=int)
    MY_value = np.dot(MY_array, coefficients_MY)
    CX_MY_UY = C*X + MY_value + UY

    if (0 < CX_MY_UY < 1) or (1 < CX_MY_UY < 2):
        return 1
    else:
        return 0





def calculate_X(MX, UX):
    num_observed_features = 15  # Observed features의 개수
    C = -0.77953605542

    bernoulli_params_UZ = ([0.524110233482, 0.689566064108, 0.180145428970, 0.317153536644, 0.046268153873,
                      0.340145244411, 0.100912238566, 0.772038172066, 0.913108434869, 0.364272299067,
                      0.063667554704, 0.454839320009, 0.586687215140, 0.018824647595, 0.871017316787])

    bernoulli_params_UX = 0.601680857267
    bernoulli_params_UY = 0.497668975278

    # Coefficients for MX and MY
    coefficients_MX = np.array([0.843870221861 , 0.178759296447, -0.372349746729, -0.950904544846, -0.439457721339,
                                -0.725970103834, -0.791203963585, -0.843183562918, -0.68422616618, -0.782051030131,
                                -0.434420454146, -0.445019418094, 0.751698021555, -0.185984172192, 0.191948271392])
                                #0.401334543567 ,  0.331387702568, 0.522595634402, -0.928734581669, 0.203436441511])

    coefficients_MY = np.array([-0.453251661832,  0.424563325534, 0.0924810605305 , 0.312680246141, 0.7676961338,
                                0.124337421843, -0.435341306455, 0.248957751703, -0.161303883519,-0.537653062121,
                                -0.222087991408, 0.190167775134, -0.788147770713, -0.593030174012, -0.308066297974])
                                #0.218776507777, -0.751253645088, -0.11151455376 , 0.785227235182, -0.568046522383])

    MX_array = np.array(MX, dtype=float) 
    MX_value = np.dot(MX_array, coefficients_MX)
    if MX_value + UX > 0.5:
        return 1
    else:
        return 0


def calculate_probabilities(subpopulation):
    num_observed_features = 15  # Observed features의 개수
    C = -0.77953605542

    bernoulli_params_UZ = ([0.524110233482, 0.689566064108, 0.180145428970, 0.317153536644, 0.046268153873,
                      0.340145244411, 0.100912238566, 0.772038172066, 0.913108434869, 0.364272299067,
                      0.063667554704, 0.454839320009, 0.586687215140, 0.018824647595, 0.871017316787])
   

    bernoulli_params_UX = 0.601680857267
    bernoulli_params_UY = 0.497668975278

    # Coefficients for MX and MY
    coefficients_MX = np.array([0.843870221861 , 0.178759296447, -0.372349746729, -0.950904544846, -0.439457721339,
                                -0.725970103834, -0.791203963585, -0.843183562918, -0.68422616618, -0.782051030131,
                                -0.434420454146, -0.445019418094, 0.751698021555, -0.185984172192, 0.191948271392])
                                #0.401334543567 ,  0.331387702568, 0.522595634402, -0.928734581669, 0.203436441511])

    coefficients_MY = np.array([-0.453251661832,  0.424563325534, 0.0924810605305 , 0.312680246141, 0.7676961338,
                                0.124337421843, -0.435341306455, 0.248957751703, -0.161303883519,-0.537653062121,
                                -0.222087991408, 0.190167775134, -0.788147770713, -0.593030174012, -0.308066297974])
                                #0.218776507777, -0.751253645088, -0.11151455376 , 0.785227235182, -0.568046522383])

    observed_features = list(subpopulation[:num_observed_features])  # 이진 문자열을 리스트로 변환
    

    

    MX_observed = coefficients_MX[:num_observed_features][np.array(list(observed_features), dtype=int)]
    MY_observed = coefficients_MY[:num_observed_features][np.array(list(observed_features), dtype=int)]
    Y = np.zeros(4)
    Y[0] = calculate_Y(0, observed_features, 0)
    Y[1] = calculate_Y(1, observed_features, 0)
    Y[2] = calculate_Y(0, observed_features, 1)
    Y[3] = calculate_Y(1, observed_features, 1)

    T0 = 1 if (Y[0] == 0 and Y[1] == 1) else 0
    T1 = 1 if (Y[2] == 0 and Y[3] == 1) else 0
    T2 = 1 if (Y[0] == 1 and Y[1] == 1) else 0
    T3 = 1 if (Y[2] == 1 and Y[3] == 1) else 0
    T4 = 1 if (Y[0] == 0 and Y[1] == 0) else 0
    T5 = 1 if (Y[2] == 0 and Y[3] == 0) else 0
    T6 = 1 if (Y[0] == 1 and Y[1] == 0) else 0
    T7 = 1 if (Y[2] == 1 and Y[3] == 0) else 0

    P_UY_0 = bernoulli.pmf(0, bernoulli_params_UY)
    P_UY_1 = bernoulli.pmf(1, bernoulli_params_UY)

    P_UX_0 = bernoulli.pmf(0, bernoulli_params_UX)
    P_UX_1 = bernoulli.pmf(1, bernoulli_params_UX)
    

    #p1 = P(Yx|c)
    P_yx = (P_UY_0 * calculate_Y(1, observed_features, 0) + P_UY_1 * calculate_Y(1, observed_features,1))


    """
    #p2= P(Yx'|c)
    P_y_x_prime = (P_UY_0 * calculate_Y(0, observed_features, 0) + P_UY_1 * calculate_Y(0, observed_features,1))
    

    #p3=P(Y'x'|c)
    P_y_prime_x_prime = (P_UY_0 * calculate_Y(1, observed_features, 0) + P_UY_1 * calculate_Y(1, observed_features,1))
    
    
    #p4=P(y|c)
    P_y = P_UY_0 * (1 - calculate_Y(0, observed_features, 0)) + P_UY_1 * (1 - calculate_Y(0, observed_features, 1))
    
    #p5 = P(y,x|c)
    P_y_and_x = (P_UX_0 * P_UY_0 * calculate_Y(calculate_X(observed_features, 0), observed_features, 0) +
                 P_UX_0 * P_UY_1 * calculate_Y(calculate_X(observed_features, 0), observed_features, 1) +
                 P_UX_1 * P_UY_0 * calculate_Y(calculate_X(observed_features, 1), observed_features, 0) + 
                 P_UX_1 * P_UY_1 * calculate_Y(calculate_X(observed_features, 1), observed_features, 1))



    #p6=P(y,x'|c)
    P_y_and_x_prime = P_UY_0 * (P_UX_0 * (1 - calculate_Y(calculate_X(observed_features, 0), observed_features, 0)) +
                                 P_UX_1 * (1 - calculate_Y(calculate_X(observed_features, 1), observed_features, 0)))


    #p7=P(y',x|c)
    P_y_prime_and_x = P_UY_0 * (P_UX_0 * calculate_Y(calculate_X(observed_features, 0), observed_features, 1) +
                                P_UX_1 * calculate_Y(calculate_X(observed_features, 1), observed_features, 1))


    #p8= P(y', x'|c)
    P_y_prime_and_x_prime = P_UY_0 * (P_UX_0 * (1 - calculate_Y(calculate_X(observed_features, 0), observed_features, 0)) +
                                       P_UX_0 * (1 - calculate_Y(calculate_X(observed_features, 0), observed_features, 1)) +
                                       P_UX_1 * (1 - calculate_Y(calculate_X(observed_features, 1), observed_features, 0)) +
                                       P_UX_1 * (1 - calculate_Y(calculate_X(observed_features, 1), observed_features, 1)))
    
    """
    return P_yx
    #return P_yx, P_y_x_prime, P_y_prime_x_prime, P_y, P_y_and_x, P_y_prime_and_x, P_y_and_x_prime, P_y_prime_and_x_prime


# Function to calculate PNS bounds with rounded probabilities
def calculate_pns_bounds(P_yx, P_y_x_prime, P_y_prime_x_prime, P_y, P_y_and_x, P_y_prime_and_x, P_y_and_x_prime, P_y_prime_and_x_prime):
    sigma = 1  # 베타-세타-감마+델타-> 1+1+1-2=1
    W = ((P_yx)-2*(P_y_x_prime)-(P_y_prime_and_x_prime))
    L = max(0, P_yx - P_y_x_prime, P_y - P_y_x_prime, P_yx - P_y)
    U = min(P_yx, P_y_prime_x_prime, P_y_and_x + P_y_prime_and_x_prime, P_yx - P_y_x_prime + P_y_and_x_prime + P_y_prime_and_x)
    
    # lower_bound = (W + sigma * L) #if sigma > 0 else round(W + sigma * U, 4)
    # upper_bound = (W + sigma * U) #if sigma > 0 else round(W + sigma * L, 4)
    lower_bound = (W + sigma * U)
    upper_bound = (W + sigma * L)

    
    return lower_bound, upper_bound

def benefit_function(s):
    # 주어진 features(c) subpopulation(s)에 대한 benefit function 계산
    # P(Yx, Y'x' | c) - P(Yx, Yx' | c) - P(Y'x, Y'x' | c) - 2 * P(Y'x, Yx' | c)
    T0 = 1 if (s[0] == 0 and s[1] == 1) else 0
    T1 = 1 if (s[2] == 0 and s[3] == 1) else 0
    T2 = 1 if (s[0] == 1 and s[1] == 1) else 0
    T3 = 1 if (s[2] == 1 and s[3] == 1) else 0
    T4 = 1 if (s[0] == 0 and s[1] == 0) else 0
    T5 = 1 if (s[2] == 0 and s[3] == 0) else 0
    T6 = 1 if (s[0] == 1 and s[1] == 0) else 0
    T7 = 1 if (s[2] == 1 and s[3] == 0) else 0

    P_UY_0 = bernoulli.pmf(0, bernoulli_params_UY)
    P_UY_1 = bernoulli.pmf(1, bernoulli_params_UY)

    benefit = (P_UY_0 * (T0 - T2 - T4 - 2 * T6) + P_UY_1 * (T1 - T3 - T5 - 2 * T7))

    return benefit

def calc_pns(subpopulation):
    probs = calculate_probabilities(subpopulation)
    lower_bound, upper_bound = calculate_pns_bounds(*probs)
    return (lower_bound+upper_bound)/2


def calculate_observed_pns_bound(subpopulation):
    bernoulli_params_UZ = [0.524110233482, 0.689566064108, 0.180145428970, 0.317153536644, 0.046268153873,
                      0.340145244411, 0.100912238566, 0.772038172066, 0.913108434869, 0.364272299067,
                      0.063667554704, 0.454839320009, 0.586687215140, 0.018824647595, 0.871017316787,
                      0.164966968157, 0.578925020078, 0.983082980658, 0.018033993991, 0.074629121266]

    P_z16_0 = bernoulli.pmf(0, bernoulli_params_UZ[15])
    P_z17_0 = bernoulli.pmf(0, bernoulli_params_UZ[16])
    P_z18_0 = bernoulli.pmf(0, bernoulli_params_UZ[17])
    P_z19_0 = bernoulli.pmf(0, bernoulli_params_UZ[18])
    P_z20_0 = bernoulli.pmf(0, bernoulli_params_UZ[19])
    P_z16_1 = bernoulli.pmf(1, bernoulli_params_UZ[15])
    P_z17_1 = bernoulli.pmf(1, bernoulli_params_UZ[16])
    P_z18_1 = bernoulli.pmf(1, bernoulli_params_UZ[17])
    P_z19_1 = bernoulli.pmf(1, bernoulli_params_UZ[18])
    P_z20_1 = bernoulli.pmf(1, bernoulli_params_UZ[19])

    pns =(P_z16_0*P_z17_0*P_z18_0*P_z19_0*P_z20_0*calc_pns(subpopulation+[0,0,0,0,0])+
          P_z16_0*P_z17_0*P_z18_0*P_z19_0+P_z20_1*calc_pns(subpopulation+[0,0,0,0,1])+
          P_z16_0*P_z17_0*P_z18_0*P_z19_1+P_z20_0*calc_pns(subpopulation+[0,0,0,1,0])+
          P_z16_0*P_z17_0*P_z18_1*P_z19_0+P_z20_0*calc_pns(subpopulation+[0,0,1,0,0])+
          P_z16_0*P_z17_1*P_z18_0*P_z19_0+P_z20_0*calc_pns(subpopulation+[0,1,0,0,0])+
          P_z16_1*P_z17_0*P_z18_0*P_z19_0+P_z20_0*calc_pns(subpopulation+[1,0,0,0,0])+
          P_z16_1*P_z17_1*P_z18_0*P_z19_0+P_z20_0*calc_pns(subpopulation+[1,1,0,0,0])+
          P_z16_1*P_z17_0*P_z18_1*P_z19_0+P_z20_0*calc_pns(subpopulation+[1,0,1,0,0])+
          P_z16_1*P_z17_0*P_z18_0*P_z19_1+P_z20_0*calc_pns(subpopulation+[1,0,0,1,0])+
          P_z16_1*P_z17_0*P_z18_0*P_z19_0+P_z20_1*calc_pns(subpopulation+[1,0,0,0,1])+
          P_z16_0*P_z17_1*P_z18_1*P_z19_0+P_z20_0*calc_pns(subpopulation+[0,1,1,0,0])+
          P_z16_0*P_z17_1*P_z18_0*P_z19_1+P_z20_0*calc_pns(subpopulation+[0,1,0,1,0])+
          P_z16_0*P_z17_1*P_z18_0*P_z19_0+P_z20_1*calc_pns(subpopulation+[0,1,0,0,1])+
          P_z16_0*P_z17_0*P_z18_1*P_z19_1+P_z20_0*calc_pns(subpopulation+[0,0,1,1,0])+
          P_z16_0*P_z17_0*P_z18_1*P_z19_0+P_z20_1*calc_pns(subpopulation+[0,0,1,0,1])+
          P_z16_0*P_z17_0*P_z18_0*P_z19_1+P_z20_1*calc_pns(subpopulation+[0,0,0,1,1])+
          P_z16_1*P_z17_1*P_z18_1*P_z19_0+P_z20_0*calc_pns(subpopulation+[1,1,1,0,0])+
          P_z16_1*P_z17_1*P_z18_0*P_z19_1+P_z20_0*calc_pns(subpopulation+[1,1,0,1,0])+
          P_z16_1*P_z17_1*P_z18_0*P_z19_0+P_z20_1*calc_pns(subpopulation+[1,1,0,0,1])+
          P_z16_1*P_z17_0*P_z18_1*P_z19_1+P_z20_0*calc_pns(subpopulation+[1,0,1,1,0])+
          P_z16_1*P_z17_0*P_z18_1*P_z19_0+P_z20_1*calc_pns(subpopulation+[1,0,1,0,1])+
          P_z16_1*P_z17_0*P_z18_0*P_z19_1+P_z20_1*calc_pns(subpopulation+[1,0,0,1,1])+
          P_z16_0*P_z17_1*P_z18_1*P_z19_1+P_z20_0*calc_pns(subpopulation+[0,1,1,1,0])+
          P_z16_0*P_z17_1*P_z18_1*P_z19_0+P_z20_1*calc_pns(subpopulation+[0,1,1,0,1])+
          P_z16_0*P_z17_1*P_z18_0*P_z19_1+P_z20_1*calc_pns(subpopulation+[0,1,0,1,1])+
          P_z16_0*P_z17_0*P_z18_1*P_z19_1+P_z20_1*calc_pns(subpopulation+[0,0,1,1,1])+
          P_z16_1*P_z17_1*P_z18_1*P_z19_1+P_z20_0*calc_pns(subpopulation+[1,1,1,1,0])+
          P_z16_1*P_z17_1*P_z18_1*P_z19_0+P_z20_1*calc_pns(subpopulation+[1,1,1,0,1])+
          P_z16_1*P_z17_1*P_z18_0*P_z19_1+P_z20_1*calc_pns(subpopulation+[1,1,0,1,1])+
          P_z16_1*P_z17_0*P_z18_1*P_z19_1+P_z20_1*calc_pns(subpopulation+[1,0,1,1,1])+
          P_z16_0*P_z17_1*P_z18_1*P_z19_1+P_z20_1*calc_pns(subpopulation+[0,1,1,1,1])+
          P_z16_1*P_z17_1*P_z18_1*P_z19_1*P_z20_1*calc_pns(subpopulation+[1,1,1,1,1])
        )


    
    return pns/32





if __name__ == "__main__":
    # Constants
    num_features = 20
    C = -0.77953605542

    # Bernoulli distributions parameters
    bernoulli_params_UZ = [0.524110233482, 0.689566064108, 0.180145428970, 0.317153536644, 0.046268153873,
                      0.340145244411, 0.100912238566, 0.772038172066, 0.913108434869, 0.364272299067,
                      0.063667554704, 0.454839320009, 0.586687215140, 0.018824647595, 0.871017316787,
                      0.164966968157, 0.578925020078, 0.983082980658, 0.018033993991, 0.074629121266]

    bernoulli_params_UX = 0.29908139311
    bernoulli_params_UY = 0.9226108109253

    # Coefficients for MX and MY
    coefficients_MX = np.array([0.843870221861 , 0.178759296447, -0.372349746729, -0.950904544846, -0.439457721339,
                                -0.725970103834, -0.791203963585, -0.843183562918, -0.68422616618, -0.782051030131,
                                -0.434420454146, -0.445019418094, 0.751698021555, -0.185984172192, 0.191948271392,
                                0.401334543567 ,  0.331387702568, 0.522595634402, -0.928734581669, 0.203436441511])

    coefficients_MY = np.array([-0.453251661832,  0.424563325534, 0.0924810605305 , 0.312680246141, 0.7676961338,
                                0.124337421843, -0.435341306455, 0.248957751703, -0.161303883519,-0.537653062121,
                                -0.222087991408, 0.190167775134, -0.788147770713, -0.593030174012, -0.308066297974,
                                0.218776507777, -0.751253645088, -0.11151455376 , 0.785227235182, -0.568046522383])

    # 샘플 개수(논문에서는 5000000개)
    num_samples = 5000000

    # Generate experimental samples
    experimental_samples = generate_exp_samples(num_samples, num_features, bernoulli_params_UZ, bernoulli_params_UX, bernoulli_params_UY, coefficients_MX, coefficients_MY, C)
    # Generate observational samples
    observational_samples = generate_obs_samples(num_samples, num_features, bernoulli_params_UZ, bernoulli_params_UX, bernoulli_params_UY, coefficients_MX, coefficients_MY, C)

    # Select samples with UZ values that occurred 1300 times or more
    selected_samples_ex = select_over_1300(experimental_samples)

    # Extract UZ values of selected samples
    selected_UZ_samples = [sample['UZ'] for sample in selected_samples_ex]


    # Convert to set to get unique combinations
    unique_selected_UZ_sets = set(map(tuple, selected_UZ_samples))
    # Convert set to list and then slice
    unique_selected_UZ_lists = [list(uz_set)[:15] for uz_set in unique_selected_UZ_sets]
    # Print unique_selected_UZ_lists
    print("Unique Selected UZ Lists:")
    for uz_list in unique_selected_UZ_lists:
        print(uz_list)
    print("Length of unique_selected_UZ_lists:", len(unique_selected_UZ_lists))

    print("Num of features selected over 1300 : ", len(unique_selected_UZ_sets))
    informer_data = []

    for idx, subpopulation in enumerate(unique_selected_UZ_lists):
        p1 = calculate_probabilities(subpopulation)
        #p1, p2, p3, p4, p5, p6, p7, p8 = calculate_probabilities(subpopulation)
        bounds = calculate_probabilities(subpopulation)
        subpopulation_values = [int(char) for char in subpopulation]
        subpopulation_label = f"subpopulation_{idx}"
        #informer_data.append({'subpopulation': subpopulation_label, 'subpopulation_values': subpopulation_values, 'P(Yx|c)': bounds})
        informer_data.append({
        'subpopulation': subpopulation_label,
        'subpopulation_values': subpopulation_values,
        'p1': p1
        # 'p2': p2,
        # 'p3': p3,
        #'p4': p4,
        # 'p5': p5,
        # 'p6': p6,
        # 'p7': p7,
        # 'p8': p8
        })

    # Example usage of informer data
    # for item in informer_data:
    #     print(f"{item['subpopulation']}, Subpopulation: {item['subpopulation_values']}, PNS Bounds: {item['P(Yx|c)']}")
    for item in informer_data:
        #print(f"{item['subpopulation']}, Subpopulation: {item['subpopulation_values']}, p1: {item['p1']}, p2: {item['p2']}, p3: {item['p3']}, p4: {item['p4']}, p5: {item['p5']}, p6: {item['p6']}, p7: {item['p7']}, p8: {item['p8']}")
        print(f"{item['subpopulation']}, Subpopulation: {item['subpopulation_values']}, p1: {item['p1']}")
    




    df = pd.DataFrame(informer_data)




    df.to_csv('P1.csv', index=False)

